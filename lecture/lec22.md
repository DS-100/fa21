---
layout: page
title: Lecture 22 – Logistic Regression, Part 1
nav_exclude: true
---

# Lecture 22 – Logistic Regression, Part 1

Presented by Presented by Fernando Perez, Suraj Rampure

Content by Suraj Rampure, Josh Hug, Joseph Gonzalez, Ani Adhikari

- [slides](https://docs.google.com/presentation/d/1ZYUMsz4tdcL5z3ZcNkrfGf3MGOQNb6Im1mQwmca0o90/edit?usp=sharing)
- [video playlist](https://youtube.com/playlist?list=PLQCcNQgUcDfoZbVqW-W-XOqBAfs88--0X)
- [code](https://data100.datahub.berkeley.edu/hub/user-redirect/git-sync?repo=https://github.com/DS-100/fa21&subPath=lec/lec22/)

A reminder – the right column of the table below contains _Quick Checks_. These are **not** required but suggested to help you check your understanding.

<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Video</th>
<th>Quick Check</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>22.0</strong> <br />Logistics</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/eCQejWU0laM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td></td>
</tr>
<tr>
<td><strong>22.1</strong> <br />Classification, and a brief overview of the machine learning taxonomy.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/n24YOheURw0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/uQ9tsyLumzqGPdE48" target="\_blank">22.1</a></td>
</tr>
<tr>
<td><strong>22.2</strong> <br />Pitfalls of using least squares to model probabilities. Creating a graph of averages to motivate the logistic regression model.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/5tO27qVS3zA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/XgpXUbUjTjZYrftp7" target="\_blank">22.2</a></td>
</tr>
<tr>
<td><strong>22.3</strong> <br />Deriving the logistic regression model from the assumption that the log-odds of the probability of belonging to class 1 is linear.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/RPeLrOS3FjA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/AmG3WPFnvdUGkDN19" target="\_blank">22.3</a></td>
</tr>
<tr>
<td><strong>22.4</strong> <br />Formalizing the logistic regression model. Exploring properties of the logistic function. Interpreting the model coefficients.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/A-mD0g3cXBo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/LDMNoNFXzgsrcz899" target="\_blank">22.4</a></td>
</tr>
<tr>
<td><strong>22.5</strong> <br />Discussing the pitfalls of using squared loss with logistic regression.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/NmxwIgbMhgc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/iQ1VqcQE7JK6571H6" target="\_blank">22.5</a></td>
</tr>
<tr>
<td><strong>22.6</strong> <br />Introducing cross-entropy loss, as a better alternative to squared loss for logistic regression.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/zFXrM6Lmlxk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/TWDmw5mdsXcTuCUB8" target="\_blank">22.6</a></td>
</tr>
<tr>
<td><strong>22.7</strong> <br />Using maximum likelihood estimation to arrive at cross-entropy loss.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/3wqXRQzJBpE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/mazXNXSmzjHLLG8a8" target="\_blank">22.7</a></td>
</tr>
<tr>
<td><strong>22.8</strong> <br />Demo of using scikit-learn to fit a logistic regression model. An overview of what's coming next.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/PWm1KYNFkSM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/g9cdfbRHEswLPCiW8" target="\_blank">22.8</a></td>
</tr>
</tbody></table>
