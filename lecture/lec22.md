---
layout: page
title: Lecture 22 – Inference for Modeling
nav_exclude: true
---

# Lecture 22 – Inference for Modeling

Presented by Suraj Rampure

Content by Suraj Rampure, John DeNero, Sam Lau, Ani Adhikari

- [slides](https://docs.google.com/presentation/d/1_bnjS_q-YerqHqjIXcCNspAcv9SI7atdkKmdmuIhwCc/edit?usp=sharing)
- [video playlist](https://www.youtube.com/playlist?list=PLQCcNQgUcDfqbFJzFXZBHlsUYcg83B-w2)
- [code](https://data100.datahub.berkeley.edu/hub/user-redirect/git-sync?repo=https://github.com/DS-100/su21&subPath=lecture/lec22/)
- [code HTML](../../resources/assets/lectures/lec22/lec22.html)

The [Data 8 textbook chapter on estimation](https://www.inferentialthinking.com/chapters/13/Estimation.html) may be very helpful.

A reminder – the right column of the table below contains _Quick Checks_. These are **not** required but suggested to help you check your understanding.

<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Video</th>
<th>Quick Check</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>22.0</strong> <br>Introduction.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/8I8w8W1IS_s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td></td>
</tr>
<tr>
<td><strong>22.1</strong> <br>A big picture overview of inference. Parameters and estimators. Bias and variance of estimators. The sample mean estimator.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/e6obRzXgTjM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSfRlQSQnDFRIvbsoyNBEwGi7Lj2w2GM_WD0daRTzUT79P-I2A/viewform?usp=sf_link" target="\_blank">22.1</a></td>
</tr>
<tr>
<td><strong>22.2</strong> <br>Using bootstrap resampling in order to estimate the sampling distribution of an estimator.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/nl_GtUlms_w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLScB96tE3EW36NIzFYuj-kCKPRms_fKHNQ_OLsQSY1Tl_XhUAw/viewform?usp=sf_link" target="\_blank">22.2</a></td>
</tr>
<tr>
<td><strong>22.3</strong> <br>Defining confidence intervals more generally. Describing and demoing how we can use the bootstrap to create confidence intervals for population parameters.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/HBpbHFd_6ow" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSfiW21UkocTN5FNKh1rAu_TMAJFDZ26ifUMjeLcvgvhhP9fAQ/viewform?usp=sf_link" target="\_blank">22.3</a></td>
</tr>
<tr>
<td><strong>22.4</strong> <br>The assumptions we make when modeling with linear regression..</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/U9ycI18u3mc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSf31UPpcwaBuT8-Zh-ZmgmHRHFkjIndGlRxaapZDnkCMN6wKQ/viewform?usp=sf_link" target="\_blank">22.4</a></td>
</tr>
<tr>
<td><strong>22.5</strong> <br>Using the bootstrap to estimate the sampling distributions of parameters in a linear regression model. Inference for the true slope of a feature.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/ZN3SL3QxuAg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSfMphcGPFnwrh02kdFXjpbLb9dkZPL2HdVGVaGPEMuGDg1GJw/viewform?usp=sf_link" target="\_blank">22.5</a></td>
</tr>
<tr>
<td><strong>22.6</strong> <br>Multicollinearity, and its impacts on the interpretability of the parameters of our model. A summary of the lecture, and a brief overview of the ML taxonomy.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/aw7DjnILY0c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSfxHF94zu50SgLHdh-bomIzRhKiCWC3NweqzOv31GHKZVFwCg/viewform?usp=sf_link" target="\_blank">22.6</a></td>
</tr>
