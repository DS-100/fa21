---
layout: page
title: Lecture 21 – Decision Trees
nav_exclude: true
---

# Lecture 21 – Decision Trees

Presented by Anthony D. Joseph

Content by Josh Hug

- [slides](https://docs.google.com/presentation/d/1oN7at3ljTNtRgRR6wO7Di8O3vK4M2pKBzPL3zomot2s/edit?usp=sharing)
- [video playlist](https://www.youtube.com/playlist?list=PLQCcNQgUcDfo7PbO4IyzKpF1S5GFf0L3a)
- [code](https://data100.datahub.berkeley.edu/hub/user-redirect/git-sync?repo=https://github.com/DS-100/fa20&subPath=lecture/lec20/)
- [code HTML](../../resources/assets/lectures/lec20/lec20.html)

A reminder – the right column of the table below contains _Quick Checks_. These are **not** required but suggested to help you check your understanding.

<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Video</th>
<th>Quick Check</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>21.0</strong> <br>Introduction</td>
<td><iframe width="300" height="300" height src="https://www.youtube.com/embed/K-c09PAl6Jg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td></td>
</tr>
<tr>
<td><strong>21.1</strong> <br>Decision tree basics. Decision trees in scikit-learn.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/fz30i-PgVBc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSffVTRqAuijoA8Q3OPv_D1od96NaWGTnxWImThSr5R2aOYdYQ/viewform" target="\_blank">21.1</a></td>
</tr>
<tr>
<td><strong>21.2</strong> <br>Overfitting and decision trees.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/IGzRkQkG2Vk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSeZ8SCiMZBBGDc9iv9RiW_XLIPK6BcX3XRrRFcE56LIH8T0Ug/viewform" target="\_blank">21.2</a></td>
</tr>
<tr>
<td><strong>21.3</strong> <br>Decision tree generation. Finding the best split. Entropy and weighted entropy.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/-mekg9slre4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSdVHVy5E5XimUHbiaj5L01wEEqIw_ztzj1uvDgVr8MGjVLlWQ/viewform" target="\_blank">21.3</a></td>
</tr>
<tr>
<td><strong>21.4</strong> <br>Restricting decision tree complexity. Preventing growth and pruning. Random forests and bagging.</td>
<td><iframe width="300" height="500" height src="https://youtube.com/embed/e8LlOnYFXcY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSe7NBp2PP2X86bGBnNvsCuZeXkkFFPK9NSuJRolu1ybp-U2Pw/viewform" target="\_blank">21.4</a></td>
</tr>
<tr>
<td><strong>21.5</strong> <br>Regression trees. Summary of decision trees, classification, and regression.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/bALgXcAaoDA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSfBOt8a-fw-OmDYjMRO415Te_PB5aUAgFaZCruviKxc6Yog2Q/viewform" target="\_blank">21.5</a></td>
</tr>
