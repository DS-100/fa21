---
layout: page
title: Lecture 25 – Inference for Modeling
nav_exclude: true
---

# Lecture 25 – Inference for Modeling

Presented by Fernando Perez and Suraj Rampure

Content by Suraj Rampure, Fernando Perez, John DeNero, Sam Lau, Ani Adhikari, Deb Nolan

- [slides](https://docs.google.com/presentation/d/18rZ6ollejp00e4WgjfD1o2VWIo1wxhWbI1jFtlnMAv4/edit?usp=sharing)
- [video playlist](https://youtube.com/playlist?list=PLQCcNQgUcDfpbA5eXHNMIidIKRKITynGD)
- [code](https://data100.datahub.berkeley.edu/hub/user-redirect/git-sync?repo=https://github.com/DS-100/fa21&subPath=lec/lec25/)

A reminder – the right column of the table below contains _Quick Checks_. These are **not** required but suggested to help you check your understanding.

<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Video</th>
<th>Quick Check</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>25.1</strong> <br />A big picture overview of inference. Parameters and estimators. Bias and variance of estimators. The sample mean estimator.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/7CFNCia9x3g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/mjmc8KUf9bhPPSBv8" target="\_blank">25.1</a></td>
</tr>
<tr>
<td><strong>25.2</strong> <br />Using bootstrap resampling in order to estimate the sampling distribution of an estimator.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/p6eGLfF89DY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/y21d1wjiD9JRB6iw5" target="\_blank">25.2</a></td>
</tr>
<tr>
<td><strong>25.3</strong> <br />Defining confidence intervals more generally. Describing and demoing how we can use the bootstrap to create confidence intervals for population parameters.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/c5dILDmjFQc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/6YotkhNf5SnyzRGZ6" target="\_blank">25.3</a></td>
</tr>
<tr>
<td><strong>25.4</strong> <br />The assumptions we make when modeling with linear regression..</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/U9ycI18u3mc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/Urfp6t9iqtCyiv589" target="\_blank">25.4</a></td>
</tr>
<tr>
<td><strong>25.5</strong> <br />Using the bootstrap to estimate the sampling distributions of parameters in a linear regression model. Inference for the true slope of a feature.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/phgDWSBWgDA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/NKhCWePxLitCEib39" target="\_blank">25.5</a></td>
</tr>
<tr>
<td><strong>25.6</strong> <br />Multicollinearity, and its impacts on the interpretability of the parameters of our model. A summary of the lecture, and a brief overview of the ML taxonomy.</td>
<td><iframe width="300" height="" src="https://youtube.com/embed/aw7DjnILY0c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></td>
<td><a href="https://forms.gle/e4SYzXWF3h8M6tr18" target="\_blank">25.6</a></td>
</tr>
</tbody></table>
